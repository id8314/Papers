{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_pickle(\"modelos.pkl\")\n",
    "data['modelo']=data['modelo'].apply(lambda x: x.split('/')[0])\n",
    "data.shape\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"modelos_ensemble.pkl\")\n",
    "print(df.shape)\n",
    "df.drop(columns=['index'],inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train=df.iloc[:,1:6]\n",
    "y=df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tf =  tf.keras.utils.to_categorical(y_train, 3)\n",
    "y_test_tf =  tf.keras.utils.to_categorical(y_test, 3)\n",
    "print(y_train_tf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def create_class_weight(labels_dict,mu=0.15):\n",
    "    total = np.sum(list(labels_dict.values()))\n",
    "    keys = labels_dict.keys()\n",
    "    class_weight = dict()\n",
    "    \n",
    "    for key in keys:\n",
    "        score = math.log(mu*total/float(labels_dict[key]))\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "    \n",
    "    return class_weight\n",
    "\n",
    "# random labels_dict\n",
    "labels_dict = {0:len(y_train[y_train==-1]),1: len(y_train[y_train==0]),2:len(y_train[y_train==1])}\n",
    "\n",
    "class_weight=create_class_weight(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This callback will stop the training when there is no improvement in the loss for the consecutive nÂº of epochs defined in patience parameter.\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define model\n",
    "t_model = Sequential()\n",
    "t_model.add(Dense(25, input_dim=5, activation='relu'))\n",
    "t_model.add(Dense(3, activation='softmax'))\n",
    "t_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "t_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "history = t_model.fit(X_train, y_train_tf, validation_data=(X_test, y_test_tf), epochs=10, callbacks=[callback],class_weight=class_weight, verbose=1)\n",
    "t_model.save('saved_model/t_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = tf.keras.models.load_model('saved_model/t_model')\n",
    "# Check its architecture\n",
    "t_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model_pred = t_model.predict(X_test)\n",
    "print(t_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "t_model_predictions = np.argmax(t_model_pred, axis=1) # select the index with the highest probability\n",
    "\n",
    "fx = (lambda x: {0:0, 1:1, 2:-1}[x])\n",
    "\n",
    "t_model_predictions = np.array([fx(x) for x in t_model_predictions]) # map the index to the corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, t_model_predictions))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba7a3bde35aa217a11f911617e58fc657d65bfc51058c319824d5f8e2d0e90e7"
  },
  "kernelspec": {
   "display_name": "Python (Papers)",
   "language": "python",
   "name": "papers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
